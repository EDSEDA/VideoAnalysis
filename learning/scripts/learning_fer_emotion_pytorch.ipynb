{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from inference.models import EmotionEstimatorModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SIZE=48\n",
    "BATCH_SIZE=200\n",
    "NUM_CLASSES=7\n",
    "EPOCHS=120\n",
    "LR=0.0005\n",
    "\n",
    "TRAIN_DATASET_PATH=\"../data/data_fer/train\"\n",
    "TEST_DATASET_PATH=\"../data/data_fer/test\"\n",
    "LOG_PATH=\"../../logs/emotion\"\n",
    "MODEL_PATH=\"models/video/emotion_model_torch.pth\"\n",
    "WEIGHTS_PATH=\"models/video/emotion_model_weights.pth\"\n",
    "TEST_IMAGE_PATH='../data/face_recognition_images/person2.3.jpg'\n",
    "TIME_FORMAT=\"%d-%m-%Y; %H:%M:%S\"\n",
    "CLASS_LABELS  = ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sadness', \"surprised\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EmotionEstimatorModel(NUM_CLASSES).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class FERDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.root_dir = directory\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.label_dict = {\"angry\": 0, \"disgusted\": 1, \"fearful\": 2, \"happy\": 3, \"neutral\": 4, \"sadness\": 5, \"surprised\": 6}\n",
    "\n",
    "        for label in os.listdir(directory):\n",
    "            label_path = os.path.join(directory, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                for img_file in os.listdir(label_path):\n",
    "                    self.images.append(os.path.join(label_path, img_file))\n",
    "                    self.labels.append(self.label_dict[label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = FERDataset(directory=TRAIN_DATASET_PATH, transform=transform)\n",
    "test_dataset = FERDataset(directory=TEST_DATASET_PATH, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Использование встроенной функции для анализа классов\n",
    "class_counts = torch.zeros(len(CLASS_LABELS))\n",
    "\n",
    "for _, labels in train_loader:\n",
    "    class_counts += torch.bincount(labels, minlength=len(CLASS_LABELS))\n",
    "\n",
    "print(\"Количество экземпляров каждого класса:\")\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"Класс {CLASS_LABELS[i]}: {int(count)} экземпляров\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_fun = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=LOG_PATH + \"/\" + datetime.now().strftime(TIME_FORMAT))\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):  # проход по датасету несколько раз\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fun(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        writer.add_scalar('Metrics/epoch_loss', running_loss  / len(train_loader), epoch)\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images, labels = images.to(device), labels\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "            \n",
    "    precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "    writer.add_scalar('Metrics/precision', precision, epoch)\n",
    "    writer.add_scalar('Metrics/recall', recall, epoch)\n",
    "    writer.add_scalar('Metrics/f1', f1, epoch)\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Функция для вычисления предсказаний\n",
    "def get_predictions(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Получение предсказаний на валидационном наборе\n",
    "all_labels, all_preds = get_predictions(model, test_loader)\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Визуализация матрицы ошибок с использованием seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Предсказанный класс')\n",
    "plt.ylabel('Истинный класс')\n",
    "plt.title('Матрица ошибок')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model, MODEL_PATH)\n",
    "torch.save(model.state_dict(), WEIGHTS_PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model = torch.load(MODEL_PATH)\n",
    "model = EmotionEstimatorModel(NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "model.eval()\n",
    "\n",
    "image = Image.open(TEST_IMAGE_PATH)\n",
    "image = transform(image).to(device)\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_emotion = predicted.item()\n",
    "\n",
    "print(f'Predicted Emotion: {predicted_emotion}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
