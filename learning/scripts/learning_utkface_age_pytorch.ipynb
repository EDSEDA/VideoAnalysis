{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "\n",
    "from inference.models import AgeEstimatorModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SIZE=48\n",
    "BATCH_SIZE=200\n",
    "EPOCHS=80\n",
    "LR=0.0005\n",
    "\n",
    "DATASET_PATH=\"../data/UTKFace_48\"\n",
    "LOG_PATH=\"../../logs/age\"\n",
    "MODEL_PATH=\"models/video/age_model_torch.pth\"\n",
    "WEIGHTS_PATH=\"models/video/age_model_weights.pth\"\n",
    "TEST_IMAGE_PATH=\"../data/face_recognition_images/person1.1.jpg\"\n",
    "TIME_FORMAT=\"%d-%m-%Y; %H:%M:%S\""
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AgeEstimatorModel().to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class UTKFaceDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.files = glob.glob(os.path.join(directory, '*.jpg'))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx]\n",
    "        image = Image.open(img_name)\n",
    "        filename = img_name.split('/')[-1]\n",
    "        age = int(filename.split('_')[0])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, age"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = UTKFaceDataset(directory='../data/UTKFace_48', transform=transform)\n",
    "train_size = int(0.85 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Использование встроенной функции для анализа классов\n",
    "class_counts = torch.zeros(90)\n",
    "\n",
    "for _, labels in train_loader:\n",
    "    class_counts += torch.bincount(labels, minlength=90)\n",
    "\n",
    "print(\"Количество экземпляров каждого класса:\")\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"Класс {i}: {int(count)} экземпляров\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_fun = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=LOG_PATH + \"/\" + datetime.now().strftime(TIME_FORMAT))\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):  # проход по датасету несколько раз\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fun(outputs.view(-1), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    writer.add_scalar('Metrics/epoch_loss', running_loss  / len(train_loader), epoch)\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images, labels = images.to(device), labels\n",
    "            outputs = model(images)\n",
    "            all_preds.extend(outputs.tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "    err = mean_absolute_error(all_labels, all_preds)\n",
    "    writer.add_scalar('Metrics/MAE', err, epoch)\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model, MODEL_PATH)\n",
    "torch.save(model.state_dict(), WEIGHTS_PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model = torch.load(MODEL_PATH)\n",
    "model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "model.eval()\n",
    "\n",
    "image = Image.open(TEST_IMAGE_PATH)\n",
    "image = transform(image)\n",
    "image = image.to(device)\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    predicted_age = output.item()\n",
    "\n",
    "print(f'Predicted Age: {predicted_age}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
