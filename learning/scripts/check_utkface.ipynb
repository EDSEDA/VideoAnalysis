{
 "cells": [
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "saved_model_age = load_model('models/video/model_age.model', compile=True)\n",
    "saved_model_gen = load_model('models/video/model_gen.model', compile=True)\n",
    "saved_model_race = load_model('models/video/model_race.model', compile=True)\n",
    "\n",
    "# saved_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# saved_model.predict([x_test])\n",
    "\n",
    "# age_model=load_model('models/video/gen_model.h5')\n",
    "# age_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_and_predict(file):\n",
    "    im = Image.open(file)\n",
    "    width, height = im.size\n",
    "    if width == height:\n",
    "        im = im.resize((96,96))\n",
    "    else:\n",
    "        if width > height:\n",
    "            left = width/2 - height/2\n",
    "            right = width/2 + height/2\n",
    "            top = 0\n",
    "            bottom = height\n",
    "            im = im.crop((left,top,right,bottom))\n",
    "            im = im.resize((96,96))\n",
    "        else:\n",
    "            left = 0\n",
    "            right = width\n",
    "            top = 0\n",
    "            bottom = width\n",
    "            im = im.crop((left,top,right,bottom))\n",
    "            im = im.resize((96,96))\n",
    "            \n",
    "    ar = np.asarray(im)\n",
    "    ar = ar.astype('float32')\n",
    "    ar /= 255.0\n",
    "    ar = ar.reshape(-1, 96, 96, 3)\n",
    "    \n",
    "    age = int(saved_model_age.predict(ar))\n",
    "    gender = np.round(saved_model_gen.predict(ar))\n",
    "    if gender == 0:\n",
    "        gender = 'male'\n",
    "    elif gender == 1:\n",
    "        gender = 'female'\n",
    "        \n",
    "    race = np.round(saved_model_race.predict(ar))\n",
    "    if race == 0:\n",
    "        race = 'white'\n",
    "    elif race == 1:\n",
    "        race = 'black'\n",
    "    elif race == 2:\n",
    "        race = 'asian'\n",
    "    elif race == 3:\n",
    "        race = 'indian'\n",
    "    elif race == 4:\n",
    "        race = 'others'\n",
    "\n",
    "    print('Age:', age, '\\nGender:', gender, '\\nRace:', race)\n",
    "    return im.resize((96,96))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "process_and_predict('/home/vorkov/Documents/x.jpg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
