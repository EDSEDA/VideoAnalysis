{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Способ 1: только инструментами yolo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7672473aea2d42f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# print(cv2.getBuildInformation())\n",
    "\n",
    "model = YOLO('models/video/yolov8n-face.pt')\n",
    "model.to(\"cuda\")\n",
    "video_path = \"rtspsrc location=rtsp://127.0.0.1:18554/test user-id=user user-pw=pass latency=0 ! rtpjitterbuffer drop-on-latency=true ! decodebin ! videoconvert ! appsink\"\n",
    "cap = cv2.VideoCapture(video_path, cv2.CAP_GSTREAMER)\n",
    "\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "while cap.isOpened():\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    start = datetime.datetime.now()\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "        results = model.track(frame, persist=True, tracker=\"../../cfg/bytetrack.yaml\")\n",
    "        if len(results) != 0 and results[0].boxes.id != None:\n",
    "\n",
    "            boxes = results[0].boxes.xywh.cpu()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "            frame = results[0].plot()\n",
    "\n",
    "            for (x, y, w, h), track_id in zip(boxes, track_ids):\n",
    "                track = track_history[track_id]\n",
    "                track.append((float(x), float(y)))\n",
    "                if len(track) > 30:\n",
    "                    track.pop(0)\n",
    "\n",
    "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "\n",
    "        end = datetime.datetime.now()\n",
    "        fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "        cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 8)\n",
    "\n",
    "        cv2.imshow(\"YOLOv8 Tracking\", frame)\n",
    "\n",
    "    else:\n",
    "        print(\"no frame\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6515a6475a9d1952",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Способ 2: с помощью deepsort_tracker"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e441898c0acd126"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('models/video/yolov8n-face.pt')\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"rtspsrc location=rtsp://127.0.0.1:18554/test user-id=user user-pw=pass latency=0 ! rtpjitterbuffer drop-on-latency=true ! decodebin ! videoconvert ! appsink\"\n",
    "cap = cv2.VideoCapture(video_path, cv2.CAP_GSTREAMER)\n",
    "\n",
    "FPS = 10  # Задайте желаемое значение FPS\n",
    "CONFIDENCE_THRESHOLD = 0.4\n",
    "GREEN = (0, 255, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])\n",
    "tracker = DeepSort(max_age=50)\n",
    "\n",
    "while cap.isOpened():\n",
    "    start = datetime.datetime.now()\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        continue\n",
    "    \n",
    "    # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "    detections = model.track(frame, persist=True)[0]\n",
    "\n",
    "    if detections.boxes.id == None:\n",
    "        continue\n",
    "        \n",
    "    # initialize the list of bounding boxes and confidences\n",
    "    results = []\n",
    "\n",
    "    ######################################\n",
    "    # DETECTION\n",
    "    ######################################\n",
    "\n",
    "    # loop over the detections\n",
    "    for data in detections.boxes.data.tolist():\n",
    "        # extract the confidence (i.e., probability) associated with the prediction\n",
    "        confidence = data[4]\n",
    "\n",
    "        # filter out weak detections by ensuring the \n",
    "        # confidence is greater than the minimum confidence\n",
    "        if float(confidence) < CONFIDENCE_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        # if the confidence is greater than the minimum confidence,\n",
    "        # get the bounding box and the class id\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "        class_id = int(data[5])\n",
    "        # add the bounding box (x, y, w, h), confidence and class id to the results list\n",
    "        results.append([[xmin, ymin, xmax - xmin, ymax - ymin], confidence, class_id])\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    # TRACKING\n",
    "    ######################################\n",
    "\n",
    "    # update the tracker with the new detections\n",
    "    tracks = tracker.update_tracks(results, frame=frame)\n",
    "    # loop over the tracks\n",
    "    for track in tracks:\n",
    "        # if the track is not confirmed, ignore it\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        # get the track id and the bounding box\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "\n",
    "        xmin, ymin, xmax, ymax = int(ltrb[0]), int(\n",
    "            ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "        # draw the bounding box and the track id\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "        cv2.rectangle(frame, (xmin, ymin - 20), (xmin + 20, ymin), GREEN, -1)\n",
    "        cv2.putText(frame, str(track_id), (xmin + 5, ymin - 8),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, WHITE, 2)\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    print(f\"Time to process 1 frame: {(end - start).total_seconds() * 1000:.0f} milliseconds\")\n",
    "    fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)\n",
    "\n",
    "    # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27d218b5c33301fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "67d986305e814af7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
